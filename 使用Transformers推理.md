æˆ‘ä»¬æä¾›äº†å‘½ä»¤è¡Œå’ŒWebå›¾å½¢ç•Œé¢ä¸¤ç§æ–¹å¼ä½¿ç”¨åŸç”ŸTransformersè¿›è¡Œæ¨ç†ã€‚

ä»¥åŠ è½½Chinese-Alpaca-7Bæ¨¡å‹ä¸ºä¾‹ï¼ˆåŠ è½½Chinese-Alpaca-Plusçš„æ–¹å¼è§ä¸‹é¢çš„**åŠ è½½Chinese-Alpaca-Plus**ï¼‰è¯´æ˜å¯åŠ¨æ–¹å¼ã€‚

### å‘½ä»¤è¡Œäº¤äº’å½¢å¼
```bash
python scripts/inference_hf.py \
    --base_model path_to_original_llama_hf_dir \
    --lora_model path_to_chinese_llama_or_alpaca_lora \
    --with_prompt \
    --interactive
```

å¦‚æœä¹‹å‰å·²æ‰§è¡Œäº†`merge_llama_with_chinese_lora_to_hf.py`è„šæœ¬å°†loraæƒé‡åˆå¹¶ï¼Œé‚£ä¹ˆæ— éœ€å†æŒ‡å®š`--lora_model`ï¼Œå¯åŠ¨æ–¹å¼æ›´ç®€å•ï¼š

```bash
python scripts/inference_hf.py \
    --base_model path_to_merged_llama_or_alpaca_hf_dir \
    --with_prompt \
    --interactive
```


å‚æ•°è¯´æ˜ï¼š

* `--base_model {base_model} `ï¼šå­˜æ”¾**HFæ ¼å¼**çš„LLaMAæ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶çš„ç›®å½•ã€‚å¦‚æœä¹‹å‰åˆå¹¶ç”Ÿæˆçš„æ˜¯PyTorchæ ¼å¼æ¨¡å‹ï¼Œ[è¯·è½¬æ¢ä¸ºHFæ ¼å¼](https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/%E6%89%8B%E5%8A%A8%E6%A8%A1%E5%9E%8B%E5%90%88%E5%B9%B6%E4%B8%8E%E8%BD%AC%E6%8D%A2#step-1-%E5%B0%86%E5%8E%9F%E7%89%88llama%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%BAhf%E6%A0%BC%E5%BC%8F)
* `--lora_model {lora_model}` ï¼šä¸­æ–‡LLaMA/Alpaca LoRAè§£å‹åæ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼Œä¹Ÿå¯ä½¿ç”¨[ğŸ¤—Model Hubæ¨¡å‹è°ƒç”¨åç§°](https://github.com/ymcui/Chinese-LLaMA-Alpaca/tree/main#model-hub)ã€‚è‹¥ä¸æä¾›æ­¤å‚æ•°ï¼Œåˆ™åªåŠ è½½`--base_model`æŒ‡å®šçš„æ¨¡å‹
* `--tokenizer_path {tokenizer_path}`ï¼šå­˜æ”¾å¯¹åº”tokenizerçš„ç›®å½•ã€‚è‹¥ä¸æä¾›æ­¤å‚æ•°ï¼Œåˆ™å…¶é»˜è®¤å€¼ä¸`--lora_model`ç›¸åŒï¼›è‹¥ä¹Ÿæœªæä¾›`--lora_model`å‚æ•°ï¼Œåˆ™å…¶é»˜è®¤å€¼ä¸`--base_model`ç›¸åŒ
* `--with_prompt`ï¼šæ˜¯å¦å°†è¾“å…¥ä¸promptæ¨¡ç‰ˆè¿›è¡Œåˆå¹¶ã€‚**å¦‚æœåŠ è½½Alpacaæ¨¡å‹ï¼Œè¯·åŠ¡å¿…å¯ç”¨æ­¤é€‰é¡¹ï¼**
* `--interactive`ï¼šä»¥äº¤äº’æ–¹å¼å¯åŠ¨ï¼Œä»¥ä¾¿è¿›è¡Œå¤šæ¬¡**å•è½®é—®ç­”**ï¼ˆæ­¤å¤„ä¸æ˜¯llama.cppä¸­çš„ä¸Šä¸‹æ–‡å¯¹è¯ï¼‰
* `--data_file {file_name}`ï¼šéäº¤äº’æ–¹å¼å¯åŠ¨ä¸‹ï¼ŒæŒ‰è¡Œè¯»å–`file_name`ä¸­çš„çš„å†…å®¹è¿›è¡Œé¢„æµ‹
* `--predictions_file {file_name}`ï¼šéäº¤äº’å¼æ–¹å¼ä¸‹ï¼Œå°†é¢„æµ‹çš„ç»“æœä»¥jsonæ ¼å¼å†™å…¥`file_name`
* `--use_cpu`: ä»…ä½¿ç”¨CPUè¿›è¡Œæ¨ç†
* `--gpus {gpu_ids}`: æŒ‡å®šä½¿ç”¨çš„GPUè®¾å¤‡ç¼–å·ï¼Œé»˜è®¤ä¸º0ã€‚å¦‚ä½¿ç”¨å¤šå¼ GPUï¼Œä»¥é€—å·åˆ†éš”ï¼Œå¦‚`0,1,2`

### Webå›¾å½¢ç•Œé¢äº¤äº’å½¢å¼

è¯¥æ–¹å¼å°†å¯åŠ¨Webå‰ç«¯é¡µé¢è¿›è¡Œäº¤äº’ï¼Œå¹¶ä¸”æ”¯æŒå¤šè½®å¯¹è¯ã€‚é™¤transformersä¹‹å¤–ï¼Œéœ€è¦å®‰è£…gradioå’Œmdtex2htmlï¼š

```bash
pip install gradio
pip install mdtex2html
```

å¯åŠ¨å‘½ä»¤å¦‚ä¸‹ï¼š

```
python scripts/gradio_demo.py \
	--base_model path_to_original_llama_hf_dir \
	--lora_model path_to_chinese_alpaca_lora
```

åŒæ ·ï¼Œå¦‚æœå·²ç»æ‰§è¡Œäº†`merge_llama_with_chinese_lora_to_hf.py`è„šæœ¬å°†loraæƒé‡åˆå¹¶ï¼Œé‚£ä¹ˆæ— éœ€å†æŒ‡å®š`--lora_model`ï¼š

```
python scripts/gradio_demo.py --base_model path_to_merged_alpaca_hf_dir 
```

å‚æ•°è¯´æ˜ï¼š

* `--base_model {base_model} `ï¼šå­˜æ”¾**HFæ ¼å¼**çš„LLaMAæ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶çš„ç›®å½•ã€‚å¦‚æœä¹‹å‰åˆå¹¶ç”Ÿæˆçš„æ˜¯PyTorchæ ¼å¼æ¨¡å‹ï¼Œ[è¯·è½¬æ¢ä¸ºHFæ ¼å¼](./æ‰‹åŠ¨æ¨¡å‹åˆå¹¶ä¸è½¬æ¢)
* `--lora_model {lora_model}` ï¼šä¸­æ–‡Alpaca LoRAè§£å‹åæ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼Œä¹Ÿå¯ä½¿ç”¨[ğŸ¤—Model Hubæ¨¡å‹è°ƒç”¨åç§°](https://github.com/ymcui/Chinese-LLaMA-Alpaca/tree/main#model-hub)ã€‚è‹¥ä¸æä¾›æ­¤å‚æ•°ï¼Œåˆ™åªåŠ è½½`--base_model`æŒ‡å®šçš„æ¨¡å‹
* `--tokenizer_path {tokenizer_path}`ï¼šå­˜æ”¾å¯¹åº”tokenizerçš„ç›®å½•ã€‚è‹¥ä¸æä¾›æ­¤å‚æ•°ï¼Œåˆ™å…¶é»˜è®¤å€¼ä¸`--lora_model`ç›¸åŒï¼›è‹¥ä¹Ÿæœªæä¾›`--lora_model`å‚æ•°ï¼Œåˆ™å…¶é»˜è®¤å€¼ä¸`--base_model`ç›¸åŒ
* `--use_cpu`: ä»…ä½¿ç”¨CPUè¿›è¡Œæ¨ç†
* `--gpus {gpu_ids}`: æŒ‡å®šä½¿ç”¨çš„GPUè®¾å¤‡ç¼–å·ï¼Œé»˜è®¤ä¸º0ã€‚å¦‚ä½¿ç”¨å¤šå¼ GPUï¼Œä»¥é€—å·åˆ†éš”ï¼Œå¦‚`0,1,2`

### åŠ è½½Chinese-Alpaca-Plus

ç›®å‰ä¸¤ä¸ªè„šæœ¬éƒ½ä¸æ”¯æŒç›´æ¥ä»LoRAæƒé‡åŠ è½½Chinese-Alpaca-Plusè¿›è¡Œæ¨ç†ï¼›å¦‚è¦è¿›è¡ŒChinese-Alpaca-Plusè¿›çš„æ¨ç†ï¼Œè¯·å…ˆåˆå¹¶æ¨¡å‹ï¼Œæµç¨‹å¦‚ä¸‹ï¼š

1. ä½¿ç”¨merge_llama_with_chinese_lora.pyåˆå¹¶loraï¼Œç”Ÿæˆå®Œæ•´çš„hfæ ¼å¼æ¨¡å‹æƒé‡ï¼š
```bash
python scripts/merge_llama_with_chinese_lora.py \
    --base_model path_to_hf_llama \
    --lora_model path_to_chinese_llama_plus_lora,path_to_chinese_alpaca_plus_lora \
    --output_type huggingface \
    --output_dir path_to_merged_chinese_alpaca_plus
```
2. ä½¿ç”¨inference_hf.pyæˆ–gradio_demo.pyåŠ è½½åˆå¹¶åçš„æ¨¡å‹è¿›è¡Œæ¨ç†ï¼Œå¦‚ï¼š
```bash
python scripts/inference_hf.py \
    --base_model path_to_merged_chinese_alpaca_plus \
    --with_prompt --interactive
```

### æ³¨æ„äº‹é¡¹

- å› ä¸åŒæ¡†æ¶çš„è§£ç å®ç°ç»†èŠ‚æœ‰å·®å¼‚ï¼Œè¯¥è„šæœ¬å¹¶ä¸èƒ½ä¿è¯å¤ç°llama.cppçš„è§£ç æ•ˆæœ
- è¯¥è„šæœ¬ä»…ä¸ºæ–¹ä¾¿å¿«é€Ÿä½“éªŒç”¨ï¼Œå¹¶æœªå¯¹æ¨ç†é€Ÿåº¦åšä¼˜åŒ–
- å¦‚åœ¨CPUä¸Šè¿è¡Œ7Bæ¨¡å‹æ¨ç†ï¼Œè¯·ç¡®ä¿æœ‰32GBå†…å­˜ï¼›å¦‚åœ¨GPUä¸Šè¿è¡Œ7Bæ¨¡å‹æ¨ç†ï¼Œè¯·ç¡®ä¿æœ‰20GBæ˜¾å­˜
