å¦‚æœæƒ³åœ¨ä¸å®‰è£…å…¶ä»–åº“æˆ–PythonåŒ…çš„æƒ…å†µä¸‹å¿«é€Ÿä½“éªŒæ¨¡å‹æ•ˆæœï¼Œå¯ä»¥ä½¿ç”¨[scripts/inference_hf.py](https://github.com/ymcui/Chinese-LLaMA-Alpaca/blob/main/scripts/inference_hf.py) è„šæœ¬å¯åŠ¨éé‡åŒ–æ¨¡å‹ã€‚è¯¥è„šæœ¬æ”¯æŒCPUå’ŒGPUçš„å•å¡æ¨ç†ã€‚ä»¥å¯åŠ¨Chinese-Alpaca-7Bæ¨¡å‹ä¸ºä¾‹ï¼Œè„šæœ¬è¿è¡Œæ–¹å¼å¦‚ä¸‹ï¼ˆè¯¥æ–¹å¼æ— æ³•åŠ è½½Chinese-Alpaca-Plusï¼Œè§**æ³¨æ„äº‹é¡¹ï¼‰ï¼š

```bash
CUDA_VISIBLE_DEVICES={device_id} python scripts/inference_hf.py \
    --base_model path_to_original_llama_hf_dir \
    --lora_model path_to_chinese_llama_or_alpaca_lora \
    --with_prompt \
    --interactive
```


å¦‚æœå·²ç»æ‰§è¡Œäº†`merge_llama_with_chinese_lora_to_hf.py`è„šæœ¬å°†loraæƒé‡åˆå¹¶ï¼Œé‚£ä¹ˆæ— éœ€å†æŒ‡å®š`--lora_model`ï¼Œå¯åŠ¨æ–¹å¼æ›´ç®€å•ï¼š

```bash
CUDA_VISIBLE_DEVICES={device_id} python scripts/inference_hf.py \
    --base_model path_to_merged_llama_or_alpaca_hf_dir \
    --with_prompt \
    --interactive
```

å‚æ•°è¯´æ˜ï¼š

* `{device_id}`ï¼šCUDAè®¾å¤‡ç¼–å·ã€‚å¦‚æœä¸ºç©ºï¼Œé‚£ä¹ˆåœ¨CPUä¸Šè¿›è¡Œæ¨ç†
* `--base_model {base_model} `ï¼šå­˜æ”¾**HFæ ¼å¼**çš„LLaMAæ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶çš„ç›®å½•ã€‚å¦‚æœä¹‹å‰åˆå¹¶ç”Ÿæˆçš„æ˜¯PyTorchæ ¼å¼æ¨¡å‹ï¼Œ[è¯·è½¬æ¢ä¸ºHFæ ¼å¼](https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/æ‰‹åŠ¨æ¨¡å‹åˆå¹¶ä¸è½¬æ¢#step-2-åˆå¹¶loraæƒé‡ç”Ÿæˆå…¨é‡æ¨¡å‹æƒé‡)
* `--lora_model {lora_model}` ï¼šä¸­æ–‡LLaMA/Alpaca LoRAè§£å‹åæ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼Œä¹Ÿå¯ä½¿ç”¨[ğŸ¤—Model Hubæ¨¡å‹è°ƒç”¨åç§°](https://github.com/ymcui/Chinese-LLaMA-Alpaca/tree/main#model-hub)ã€‚è‹¥ä¸æä¾›æ­¤å‚æ•°ï¼Œåˆ™åªåŠ è½½`--base_model`æŒ‡å®šçš„æ¨¡å‹
* `--tokenizer_path {tokenizer_path}`ï¼šå­˜æ”¾å¯¹åº”tokenizerçš„ç›®å½•ã€‚è‹¥ä¸æä¾›æ­¤å‚æ•°ï¼Œåˆ™å…¶é»˜è®¤å€¼ä¸`--lora_model`ç›¸åŒï¼›è‹¥ä¹Ÿæœªæä¾›`--lora_model`å‚æ•°ï¼Œåˆ™å…¶é»˜è®¤å€¼ä¸`--base_model`ç›¸åŒ
* `--with_prompt`ï¼šæ˜¯å¦å°†è¾“å…¥ä¸promptæ¨¡ç‰ˆè¿›è¡Œåˆå¹¶ã€‚**å¦‚æœåŠ è½½Alpacaæ¨¡å‹ï¼Œè¯·åŠ¡å¿…å¯ç”¨æ­¤é€‰é¡¹ï¼**
* `--interactive`ï¼šä»¥äº¤äº’æ–¹å¼å¯åŠ¨ï¼Œä»¥ä¾¿è¿›è¡Œå¤šæ¬¡**å•è½®é—®ç­”**ï¼ˆæ­¤å¤„ä¸æ˜¯llama.cppä¸­çš„ä¸Šä¸‹æ–‡å¯¹è¯ï¼‰
* `--data_file {file_name}`ï¼šéäº¤äº’æ–¹å¼å¯åŠ¨ä¸‹ï¼ŒæŒ‰è¡Œè¯»å–`file_name`ä¸­çš„çš„å†…å®¹è¿›è¡Œé¢„æµ‹
* `--predictions_file {file_name}`ï¼šéäº¤äº’å¼æ–¹å¼ä¸‹ï¼Œå°†é¢„æµ‹çš„ç»“æœä»¥jsonæ ¼å¼å†™å…¥`file_name`

æ³¨æ„äº‹é¡¹ï¼š

- å› ä¸åŒæ¡†æ¶çš„è§£ç å®ç°ç»†èŠ‚æœ‰å·®å¼‚ï¼Œè¯¥è„šæœ¬å¹¶ä¸èƒ½ä¿è¯å¤ç°llama.cppçš„è§£ç æ•ˆæœ
- è¯¥è„šæœ¬ä»…ä¸ºæ–¹ä¾¿å¿«é€Ÿä½“éªŒç”¨ï¼Œå¹¶æœªå¯¹å¤šæœºå¤šå¡ã€ä½å†…å­˜ã€ä½æ˜¾å­˜ç­‰æƒ…å†µç­‰æ¡ä»¶åšä»»ä½•ä¼˜åŒ–
- å¦‚åœ¨CPUä¸Šè¿è¡Œ7Bæ¨¡å‹æ¨ç†ï¼Œè¯·ç¡®ä¿æœ‰32GBå†…å­˜ï¼›å¦‚åœ¨GPUä¸Šè¿è¡Œ7Bæ¨¡å‹æ¨ç†ï¼Œè¯·ç¡®ä¿æœ‰20GBæ˜¾å­˜
- inference_hf.pyæš‚ä¸æ”¯æŒä»loraæƒé‡åŠ è½½Chinese-Alpaca-Plusè¿›è¡Œæ¨ç†ï¼›å¦‚è¦è¿›è¡ŒChinese-Alpaca-Plusè¿›çš„æ¨ç†ï¼Œå»ºè®®å…ˆåˆå¹¶æ¨¡å‹ï¼Œæµç¨‹å¦‚ä¸‹ï¼š
1. ä½¿ç”¨merge_llama_with_chinese_lora.pyåˆå¹¶loraï¼Œç”Ÿæˆå®Œæ•´çš„hfæ ¼å¼æ¨¡å‹æƒé‡ï¼š
```bash
python merge_llama_with_chinese_lora.py \
    --base_model path_to_hf_llama \
    --lora_model path_to_chinese_llama_plus_lora,path_to_chinese_alpaca_plus_lora \
    --output_type huggingface \
    --output_dir path_to_merged_chinese_alpaca_plus
```
2. ä½¿ç”¨inference_hf.pyåŠ è½½åˆå¹¶åçš„æ¨¡å‹è¿›è¡Œæ¨ç†ï¼š
```bash
python inference_hf.py \
    --base_model path_to_merged_chinese_alpaca_plus \
    --with_prompt --interactive
```
