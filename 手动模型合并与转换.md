### å‡†å¤‡å·¥ä½œ

1. è¿è¡Œå‰ç¡®ä¿æ‹‰å–ä»“åº“æœ€æ–°ç‰ˆä»£ç ï¼š`git pull`
2. ç¡®ä¿æœºå™¨æœ‰è¶³å¤Ÿçš„å†…å­˜åŠ è½½å®Œæ•´æ¨¡å‹ï¼ˆä¾‹å¦‚7Bæ¨¡å‹éœ€è¦13-15Gï¼‰ä»¥è¿›è¡Œåˆå¹¶æ¨¡å‹æ“ä½œã€‚
3. **åŠ¡å¿…ç¡®è®¤åŸºæ¨¡å‹å’Œä¸‹è½½çš„LoRAæ¨¡å‹å®Œæ•´æ€§ï¼Œæ£€æŸ¥æ˜¯å¦ä¸[SHA256.md](https://github.com/ymcui/Chinese-LLaMA-Alpaca/blob/main/SHA256.md)æ‰€ç¤ºçš„å€¼ä¸€è‡´**ï¼Œå¦åˆ™æ— æ³•è¿›è¡Œåˆå¹¶æ“ä½œã€‚åŸç‰ˆLLaMAåŒ…å«ï¼š`tokenizer.model`ã€`tokenizer_checklist.chk`ã€`consolidated.*.pth`ã€`params.json`
4. ä¸»è¦ä¾èµ–åº“å¦‚ä¸‹ï¼ˆpython>=3.9ï¼‰ï¼Œ**è¯·å®‰è£…æŒ‡å®šç‰ˆæœ¬ï¼Œå¦åˆ™åˆå¹¶åæ— æ³•æ¯”å¯¹SHA256æ ¡éªŒå€¼**ï¼š

```bash
pip install torch==1.13.1
pip install transformers==4.28.1
pip install sentencepiece==0.1.97
pip install peft==0.3.0
```

*æ³¨æ„ï¼šç»è¿‡å¤šæ–¹æ¯”å¯¹ï¼ŒHuggingFaceæ¨¡å‹åº“ä¸­çš„`elinas/llama-7b-hf-transformers-4.29`ä¸åŸç‰ˆllamaæ¨¡å‹ç¦»çº¿è½¬æ¢ä¸ºHFæ ¼å¼åçš„SHA256ä¸€è‡´ï¼ˆå·²éªŒè¯7B/13B/33Bï¼‰ã€‚å¦‚æœä½ è¦ä½¿ç”¨ï¼Œåˆ™åº”ç¡®ä¿æ»¡è¶³ç›¸åº”ä½¿ç”¨è®¸å¯ï¼Œæˆ‘ä»¬ä¸å¯¹å…¶åˆè§„æ€§åšå‡ºä»»ä½•ä¿è¯ï¼ˆuse at your own riskï¼‰ã€‚*


### Step 1: å°†åŸç‰ˆLLaMAæ¨¡å‹è½¬æ¢ä¸ºHFæ ¼å¼

è¯·ä½¿ç”¨[ğŸ¤—transformers](https://huggingface.co/docs/transformers/installation#install-from-source)æä¾›çš„è„šæœ¬[convert_llama_weights_to_hf.py](https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama/convert_llama_weights_to_hf.py)ï¼Œå°†åŸç‰ˆLLaMAæ¨¡å‹è½¬æ¢ä¸ºHuggingFaceæ ¼å¼ã€‚å°†åŸç‰ˆLLaMAçš„`tokenizer.model`æ”¾åœ¨`--input_dir`æŒ‡å®šçš„ç›®å½•ï¼Œå…¶ä½™æ–‡ä»¶æ”¾åœ¨`${input_dir}/${model_size}`ä¸‹ã€‚æ‰§è¡Œä»¥ä¸‹è„šæœ¬ï¼ˆæ³¨æ„è¿™ä¸ªè„šæœ¬è·¯å¾„æŒ‡çš„æ˜¯transformersçš„è·¯å¾„ï¼Œä¸æ˜¯æœ¬é¡¹ç›®çš„ç›®å½•ï¼‰åï¼Œ`--output_dir`ä¸­å°†å­˜æ”¾è½¬æ¢å¥½çš„HFç‰ˆæƒé‡ã€‚

```bash
python src/transformers/models/llama/convert_llama_weights_to_hf.py \
    --input_dir path_to_original_llama_root_dir \
    --model_size 7B \
    --output_dir path_to_original_llama_hf_dir
```

`--output_dir`ç›®å½•ä¸‹ä¼šç”ŸæˆHFæ ¼å¼çš„æ¨¡å‹æ–‡ä»¶ï¼Œè¯¸å¦‚ï¼š

```
config.json
generation_config.json
pytorch_model-00001-of-00002.bin
pytorch_model-00002-of-00002.bin
pytorch_model.bin.index.json
special_tokens_map.json
tokenizer_config.json
tokenizer.json
tokenizer.model
```

### Step 2: åˆå¹¶LoRAæƒé‡ï¼Œç”Ÿæˆå…¨é‡æ¨¡å‹æƒé‡

è¿™ä¸€æ­¥éª¤ä¼šå¯¹åŸç‰ˆLLaMAæ¨¡å‹ï¼ˆHFæ ¼å¼ï¼‰æ‰©å……ä¸­æ–‡è¯è¡¨ï¼Œåˆå¹¶LoRAæƒé‡å¹¶ç”Ÿæˆå…¨é‡æ¨¡å‹æƒé‡ã€‚æ­¤å¤„å¯ä»¥é€‰æ‹©è¾“å‡ºPyTorchç‰ˆæœ¬æƒé‡ï¼ˆ`.pth`æ–‡ä»¶ï¼‰æˆ–è€…è¾“å‡ºHuggingFaceç‰ˆæœ¬æƒé‡ï¼ˆ`.bin`æ–‡ä»¶ï¼‰ã€‚

- `.pth`æ–‡ä»¶å¯ç”¨äºï¼š[ä½¿ç”¨llama.cppå·¥å…·è¿›è¡Œé‡åŒ–å’Œéƒ¨ç½²](https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/llama.cppé‡åŒ–éƒ¨ç½²)

- `.bin`æ–‡ä»¶å¯ç”¨äºï¼š[ä½¿ç”¨Transformersè¿›è¡Œæ¨ç†](https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/ä½¿ç”¨Transformersæ¨ç†)ã€[ä½¿ç”¨text-generation-webuiæ­å»ºç•Œé¢](https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/ä½¿ç”¨text-generation-webuiæ­å»ºç•Œé¢)

æ³¨æ„ï¼Œä¸åŒæ¨¡å‹çš„åˆå¹¶æ–¹å¼ä¸åŒã€‚è¯·é˜…è¯»ä»¥ä¸‹æŒ‡å—å¹¶ä¸¥æ ¼æŒ‰ç…§æ­¥éª¤è¿›è¡Œã€‚

#### å•LoRAæƒé‡åˆå¹¶ï¼ˆé€‚ç”¨äº Chinese-LLaMA, Chinese-LLaMA-Plus, Chinese-Alpacaï¼‰

æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

```bash
python scripts/merge_llama_with_chinese_lora.py \
    --base_model path_to_original_llama_hf_dir \
    --lora_model path_to_chinese_llama_or_alpaca_lora \
    --output_type [pth|huggingface] \
    --output_dir path_to_output_dir 
```

å‚æ•°è¯´æ˜ï¼š

- `--base_model`ï¼šå­˜æ”¾HFæ ¼å¼çš„LLaMAæ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶çš„ç›®å½•ï¼ˆStep 1ç”Ÿæˆï¼‰
- `--lora_model`ï¼šä¸­æ–‡LLaMA/Alpaca LoRAè§£å‹åæ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼Œä¹Ÿå¯ä½¿ç”¨[ğŸ¤—Model Hubæ¨¡å‹è°ƒç”¨åç§°](https://github.com/ymcui/Chinese-LLaMA-Alpaca/tree/main#model-hub)
- `--output_type`: æŒ‡å®šè¾“å‡ºæ ¼å¼ï¼Œå¯ä¸º`pth`æˆ–`huggingface`ã€‚è‹¥ä¸æŒ‡å®šï¼Œé»˜è®¤ä¸º`pth`
- `--output_dir`ï¼šæŒ‡å®šä¿å­˜å…¨é‡æ¨¡å‹æƒé‡çš„ç›®å½•ï¼Œé»˜è®¤ä¸º`./`
- ï¼ˆå¯é€‰ï¼‰`--offload_dir`ï¼šå¯¹äºä½å†…å­˜ç”¨æˆ·éœ€è¦æŒ‡å®šä¸€ä¸ªoffloadç¼“å­˜è·¯å¾„

#### å¤šLoRAæƒé‡åˆå¹¶ï¼ˆé€‚ç”¨äºChinese-Alpaca-Plusï¼‰

åˆå¹¶Chinese-Alpaca-Pluséœ€è¦æä¾›ä¸¤ä¸ªLoRAæƒé‡ï¼Œåˆ†åˆ«ä¸ºChinese-LLaMA-Plus-LoRAå’ŒChinese-Alpaca-Plus-LoRAã€‚æ‰§è¡Œä»¥ä¸‹å‘½ä»¤å®Œæˆåˆå¹¶ï¼š

```bash
python scripts/merge_llama_with_chinese_lora.py \
    --base_model path_to_original_llama_hf_dir \
    --lora_model path_to_chinese_llama_plus_lora,path_to_chinese_alpaca_plus_lora \
    --output_type [pth|huggingface] \
    --output_dir path_to_output_dir 
```

å‚æ•°é€‰é¡¹å«ä¹‰ä¸å•LoRAæƒé‡åˆå¹¶ä¸­çš„å«ä¹‰ç›¸åŒã€‚éœ€è¦æ³¨æ„çš„æ˜¯` --lora_model`å‚æ•°åè¦æä¾›ä¸¤ä¸ªlora_modelçš„åœ°å€ï¼Œç”¨é€—å·åˆ†éš”ã€‚âš ï¸ **ä¸¤ä¸ªLoRAæ¨¡å‹çš„é¡ºåºå¾ˆé‡è¦ï¼Œä¸èƒ½é¢ å€’ã€‚å…ˆå†™LLaMA-Plus-LoRAç„¶åå†™Alpaca-Plus-LoRAã€‚** 

### Step 3: åˆå¹¶åæ£€æŸ¥ï¼ˆé‡è¦ï¼ï¼‰

**åˆå¹¶å®ŒæˆååŠ¡å¿…æ£€æŸ¥SHA256ï¼åˆå¹¶å®ŒæˆååŠ¡å¿…æ£€æŸ¥SHA256ï¼åˆå¹¶å®ŒæˆååŠ¡å¿…æ£€æŸ¥SHA256ï¼**

åˆå¹¶åpthæ–‡ä»¶çš„SHA256ï¼šhttps://github.com/ymcui/Chinese-LLaMA-Alpaca/blob/main/SHA256.md

å¦å¤–ï¼Œä¹Ÿå¯å‚è€ƒæˆ‘ä»¬çš„è§£ç ç¤ºä¾‹ï¼Œä½¿ç”¨ç›¸åŒçš„è§£ç å‚æ•°è¿›è¡Œæµ‹è¯•ã€‚å¦‚æœå¤šæ¬¡è¿è¡Œåç»“æœä¸ç¤ºä¾‹ç›¸å·®è¾ƒå¤§ï¼Œåˆ™å¯èƒ½è¡¨ç¤ºåˆå¹¶åçš„æ¨¡å‹å¯èƒ½å­˜åœ¨ä¸å®Œæ•´ç­‰é—®é¢˜ã€‚å¼ºçƒˆå»ºè®®æ¯”å¯¹ä»¥ä¸ŠSHA256å€¼ï¼Œç¡®ä¿æ¨¡å‹æ­£ç¡®ã€‚
